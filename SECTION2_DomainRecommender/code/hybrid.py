# ============================================================================ 
# Group: 19
# Team Members:
# - Youssef Ekrami Elsayed 
# - Abdelrahman Mohamed Negm
# - Hagar Mohamed Badawy
# - Dareen Ashraf Mosa
# ============================================================================

# -*- coding: utf-8 -*-
"""Hybrid

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UUqdjBubAAFyVyhVYwcHIYcFnrZoDe44

**Part 3: Hybrid Approach**

8. Collaborative Filtering Integration

8.1. Implement ONE CF approach:
User-based OR Item-based CF
"""

import collaborative as cf
# from collaborative import predicted_df
import pandas as pd
import numpy as np
import os
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import random

# Define relative paths
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_DIR = os.path.join(BASE_DIR, "SECTION2_DomainRecommender", "data")
RESULTS_DIR = os.path.join(BASE_DIR, "SECTION2_DomainRecommender", "results")
CODE_DIR = os.path.join(BASE_DIR, "SECTION2_DomainRecommender", "code")

DATASET_PATH = os.path.join(DATA_DIR, "cleaned_financial_data.csv")
TABLES_DIR = os.path.join(RESULTS_DIR, "tables", "hybrid")
PLOTS_DIR = os.path.join(RESULTS_DIR, "plots", "hybrid")

# Create directories if they don't exist
os.makedirs(TABLES_DIR, exist_ok=True)
os.makedirs(PLOTS_DIR, exist_ok=True)

df = pd.read_csv(DATASET_PATH)

user_item_matrix = df.pivot_table(
    index="user_id",
    columns="item_id",
    values="rating"
)

user_item_matrix_filled = user_item_matrix.fillna(0)

"""9.Hybrid Recommendation Strategy

9.1. Implement ONE hybrid approach:

 Option A: Weighted Hybrid:

"""

item_content = df[
    ['item_id', 'title', 'primary_topic', 'subtopic',
     'difficulty', 'content_type', 'description', 'summary']
].drop_duplicates()

item_content.fillna("", inplace=True)

item_content['content'] = (
    item_content['title'] + " " +
    item_content['primary_topic'] + " " +
    item_content['subtopic'] + " " +
    item_content['difficulty'] + " " +
    item_content['content_type'] + " " +
    item_content['description'] + " " +
    item_content['summary']
)

item_content = item_content[['item_id', 'content']]

tfidf = TfidfVectorizer(stop_words='english', max_features=5000)
tfidf_matrix = tfidf.fit_transform(item_content['content'])

content_similarity = cosine_similarity(tfidf_matrix)

content_sim_df = pd.DataFrame(
    content_similarity,
    index=item_content['item_id'],
    columns=item_content['item_id']
)

def content_based_scores(user_id):
    user_items = df[df['user_id'] == user_id]['item_id'].unique()
    scores = {}

    for item in user_items:
        if item in content_sim_df.index:
            for sim_item, sim_score in content_sim_df[item].items():
                if sim_item not in user_items:
                    scores[sim_item] = max(scores.get(sim_item, 0), sim_score)

    return pd.Series(scores)

def cf_scores(user_id):
    preds = cf.predicted_df.loc[user_id]
    seen = user_item_matrix.loc[user_id].notna()
    return preds[~seen]

def hybrid_recommendation(user_id, alpha=0.5, top_n=10):
    cb = content_based_scores(user_id)
    cf = cf_scores(user_id)

    hybrid = {}

    for item in cf.index:
        hybrid[item] = alpha * cb.get(item, 0) + (1 - alpha) * cf[item]

    return pd.Series(hybrid).sort_values(ascending=False).head(top_n)

results = {}

for alpha in [0.3, 0.5, 0.7]:
    results[alpha] = hybrid_recommendation(user_id=10, alpha=alpha)

for alpha, recs in results.items():
    recs.reset_index().to_csv(
        os.path.join(TABLES_DIR, f"hybrid_weighted_alpha_{alpha}.csv"),
        index=False
    )

"""Option A was preferred because it provides a smooth and controllable integration of content relevance and collaborative signals, which is more suitable for the educational and sensitive nature of financial literacy content

10. Cold-Start Handling

10.1. Demonstrate cold-start solution:

Test on users with 3, 5, and 10 ratings
"""

user_counts = df.groupby("user_id").size()

user_3 = user_counts[user_counts == 3].index[0]
user_5 = user_counts[user_counts == 5].index[0]
user_10 = user_counts[user_counts == 10].index[0]

def hybrid_recommendation(user_id, alpha=0.5, top_n=5):
    cb = content_based_scores(user_id)
    cf = cf_scores(user_id)

    hybrid = {}
    for item in cf.index:
        hybrid[item] = alpha * cb.get(item, 0) + (1 - alpha) * cf[item]

    return pd.Series(hybrid).sort_values(ascending=False).head(top_n)

res_3 = hybrid_recommendation(user_3, alpha=0.7)
res_3.reset_index().to_csv(
    os.path.join(TABLES_DIR, "hybrid_cold_user_3.csv"), 
    index=False
)

res_5 = hybrid_recommendation(user_5, alpha=0.5)
res_5.reset_index().to_csv(
    os.path.join(TABLES_DIR, "hybrid_cold_user_5.csv"), 
    index=False
)

res_10 = hybrid_recommendation(user_10, alpha=0.3)
res_10.reset_index().to_csv(
    os.path.join(TABLES_DIR, "hybrid_cold_user_10.csv"), 
    index=False
)

"""Compare with popularity baseline

11.Baseline Comparison

11.1. Compare your hybrid system against:
Random recommendations, most popular items, and pure content-based
"""

popular_items = (
    df.groupby("item_id")
    .size()
    .sort_values(ascending=False)
    .head(5)
    .index
)

popular_df = pd.DataFrame({
    "recommended_item": popular_items,
    "reason": "Most Popular"
})

popular_df.to_csv(
    os.path.join(TABLES_DIR, "baseline_popular.csv"), 
    index=False
)
popular_df

all_items = df["item_id"].unique()
random_items = random.sample(list(all_items), 5)

random_df = pd.DataFrame({
    "recommended_item": random_items,
    "reason": "Random"
})

random_df.to_csv(
    os.path.join(TABLES_DIR, "baseline_random.csv"), 
    index=False
)
random_df

user_id = user_3

content_based_result = content_based_scores(user_id).head(5).reset_index()
content_based_result.columns = ["recommended_item", "score"]

content_based_result.to_csv(
    os.path.join(TABLES_DIR, "baseline_content_based.csv"), 
    index=False
)
content_based_result

hybrid_result = hybrid_recommendation(user_id, alpha=0.7).reset_index()
hybrid_result.columns = ["recommended_item", "score"]

hybrid_result.to_csv(
    os.path.join(TABLES_DIR, "hybrid_result.csv"), 
    index=False
)
hybrid_result

"""11.2. Create comparison table showing all metrics."""

comparison_data = {
    "Approach": [
        "Random",
        "Most Popular",
        "Content-Based",
        "Hybrid (Weighted)"
    ],
    "Personalization": [
        "Low",
        "Low",
        "High",
        "High"
    ],
    "Cold-Start Support": [
        "Medium",
        "Medium",
        "High",
        "High"
    ],
    "Diversity": [
        "High",
        "Low",
        "Medium",
        "High"
    ],
    "Relevance to User Profile": [
        "Low",
        "Medium",
        "High",
        "High"
    ],
    "Uses User Behavior": [
        "No",
        "Yes (global)",
        "No",
        "Yes (personalized)"
    ]
}

comparison_table = pd.DataFrame(comparison_data)
comparison_table

comparison_table.to_csv(
    os.path.join(TABLES_DIR, "baseline_comparison_table.csv"), 
    index=False
)

"""Which approach was performed best?

The weighted hybrid recommendation approach performed best because it combined personalization from collaborative filtering with relevance from content-based features.

How well does the hybrid handle cold-start?

The hybrid approach handled cold-start effectively by relying more on content-based recommendations when user interaction data was limited and gradually incorporating collaborative filtering as more data became available."""